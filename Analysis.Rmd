---
title: "Analysis"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

This is our analysis of the [Science Museum of Minnesota](https://www.smm.org) member data for participation in the [Analyze This!](http://www.meetup.com/AnalyzeThis/) 2016 Science Museum Summer Challenge.

### Keep It Statistically Simple Team

- Justin Grammens <justin@recursiveawesome.com>
- Tron Kotz <tron.kotz@gmail.com>
- Lance Kaiwei <lancekaiwei@gmail.com>
- Saad Khan <saadkhan321@gmail.com>
- Peter Edstrom <peter@softwareforgood.com>


## Import the data into dataframes

Let's start by pulling the data into local variables. Noted here so you can see where the data comes from. If you do not have a copy of the `SMM Competitor Workbook 5.25.16.xlsx` file, please contact Beth Varro at <bvarro@smm.org> and fill out an NDA.

```{r data}
library(readxl)
workbook.file <- "data/SMM Competitor Workbook 5.25.16.xlsx"
ad <- read_excel(workbook.file, sheet="Analytics Dataset")
ml <- read_excel(workbook.file, sheet="Mbrshp Level")
pm <- read_excel(workbook.file, sheet="Pmt Mthd")
sc <- read_excel(workbook.file, sheet="Sales Channel")
o1 <- read_excel(workbook.file, sheet="Offer on 1st Ren Notice")
ei <- read_excel(workbook.file, sheet="Email Indicators")
eo <- read_excel(workbook.file, sheet="EMail Options")
d1 <- read_excel(workbook.file, sheet="Demo_1")
zc <- read_excel(workbook.file, sheet="Zip Code")
kp <- read_excel(workbook.file, sheet="Key people on Membership")
nv <- read_excel(workbook.file, sheet="Num Visits")
cs <- read_excel(workbook.file, sheet="CSIs")
co <- read_excel(workbook.file, sheet="Communication")


workbook.file <- "data/The Data Dictionary 5.25.16.xlsx"
pe <- read_excel(workbook.file, sheet="Simplified Program and Events")
```

## Clean some data

Remove a few records that do not have matching records in the `ad` data frame per the [thread](http://www.meetup.com/AnalyzeThis/events/230716702/?read=1&_af=event&_af_eid=230716702&https=off) on Meetup.

```{r clean data}
cs <- cs[cs$`ID Number`!=6871452,]
pm <- pm[pm$`ID Number`!=6993112,]
sc <- sc[sc$`ID Number`!=6993112,]
o1 <- o1[o1$`ID Number`!=6993112,]
nv <- nv[nv$`ID Number`!=6993112,]
co <- co[co$`ID Number`!=6993112,]
```

## Basic Visuals

Let's take a first pass to see what the data looks like. 

```{r ad prep}
library(ggplot2)
ad$`Initiation Month` <- cut(ad$`Initiation Date`, breaks="month")
ad$`Expiration Month` <- cut(ad$`Expiration Date`, breaks="month")
```

Here we have a bar chart showing in what months the initiations are found.

```{r ad chart for Initiations, echo=FALSE, fig.height=2}
ggplot(data=ad,
  aes(`Initiation Month`,1)) +
  stat_summary(fun.y=sum, geom="bar") +
  theme(axis.text.x=element_text(angle = 45, hjust = 1), axis.title.x=element_blank()) +
  ylab("Initiation Count")
```

And this shows the expirations by month. Showing expirations as a negative count.

```{r ad chart for Expiration, echo=FALSE, fig.height=2}
ggplot(data=ad,
  aes(`Expiration Month`,-1)) +
  stat_summary(fun.y=sum, geom="bar") +
  theme(axis.text.x=element_text(angle = 45, hjust = 1), axis.title.x=element_blank()) +
  ylab("Expiration Count")
```

First thing that jumps out at me is that there is a huge spike in March, and a very quiet month in Septemeber. Would love to see a longer period of time, as I suspect there is some seasonality to the membership. Perhaps the low Septemeber month is because school is starting, and the high March month is because schools are raising awarness to the SMM through end-of-year field trips? 

Also, you can see the initiation and expiration charts are nearly identical opposites. How many of the first-year members renew? 

```{r how many renew}
table(ad[,c("Renew")])
```

As it turns out, not many. About 12% of the population renewed (1) and 7570 did not (0). Having precisly 1000 renewals seems odd and makes me wonder how this data was filtered to begin with. 

## Sample the Data

This is where I think we should divide up the data into a few groups - data to create the model, the set we'll be tested on, and then a group or two for testing? Glad for anyone to jump in here and provide some insight. 

## Modeling Data / Regression Analysis

Breaking this up into two sections. The first section is As-Is. This is where I'm thinking we provide analysis on the data without making any major changes to it. The second section focuses on doing analysis on 2nd order data. For example: calculate the duration of the membership in days and use that in looking for correlations, or trying to quantify good CSIs from neutral and bad ones before correlating. Or calculating distance by the zip code, etc.

### Modeling Data As-Is

Starting with a linear regression on the Membership Level Discounts.

```{r Membership Level Discounts}
ad.ml <- merge(ad, ml, by="ID Number")
fit <- lm(Renew ~ Discount, data=ad.ml)
summary(fit)
```

This tells us that with regression coefficients near zero and a multiple r-squared value less than 1%, that **discounts are not a factor in renewals**.

Lets look at Membership Levels next.

```{r Membership Levels}
fit <- lm(Renew ~ Mbr1 + Mbr2 + Mbr1:Mbr2, data=ad.ml)
summary(fit)
```

TODO: add analysis on what the summary means.

### Modeling Data with Computed Columns

Program and Event Data

We reviewed the Program and Event data and simplified each event down to types of events. We made a number of assumptions in this process, including things such as "Small upcharge" was the same as an "Upcharge exhibit" and "Free temporary exhibit" is the same as "free exhibit". The goal here being to simplify the types of events, but have enough of them that we can see reasonabally-credible trends. There are certainly opportunities to look for one-off coorelations ("B-feature; played 2 times/day to give some variety") however because these are all single instances, or near-single instances, we felt that was not a valuable exercise at this time. 

The data, therefore, becaome:

```{r program and event table}
pe
```

To link these dates up to members for analysls, we had to take a few steps:

```{r nearest future start}
#function to look up the next event
nextNearestEvent <- function(d,t){
  a <- pe[as.Date(pe$"Start Date") >= t,]
  b <- min(a$"Start Date")
  return(b)
}

#create a column with that event
# TODO, this isn't working yet
# ad$nextEventDate <- lapply(ad$"Expiration Date", nextNearestEvent, t="Expiration Date")

#then do that for multiple event types
# TODO
```

Merge all of the tabs for a massive csv

```{r merge}

df <- merge(ad, ml, by="ID Number")
df <- merge(df, pm, by="ID Number")
df <- merge(df, sc, by="ID Number")
df <- merge(df, o1, by="ID Number")
df <- merge(df, ei, by="ID Number")
df <- merge(df, eo, by="ID Number")
df <- merge(df, d1, by="ID Number")
df <- merge(df, zc, by="ID Number")
df <- merge(df, kp, by="ID Number")
df <- merge(df, nv, by="ID Number")
#df <- merge(df, cs, by="ID Number") #SKIP THIS since there are only 1192 observations
df <- merge(df, co, by="ID Number")
write.table(df, "all.columns.csv", col.names=TRUE, row.names=FALSE, sep=",")

```


What columns are most important? 

```{r important columns}

#cols that can't compare
df.sub <- df[,-which(names(df) %in% c("Initiation Date", "Expiration Date", "Test or Train?", "Mbr1", "Mbr2", "Discount"))]

for (n in colnames(df.sub)){
  print(paste("Looking up:", n))
  # comment these lines out to see the correlation for each column, not sure why it doesn't work with knitr
  #c <- cor(df.sub$Renew, df.sub[n], use="complete.obs")
  #print(paste("  cor=",c))
}

```
